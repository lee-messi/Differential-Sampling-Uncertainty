{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, math, base64\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image lookup CSV file\n",
    "ganfd = pd.read_csv('../GANFD/image_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(current_directory, \"../GANFD/Images\"))\n",
    "images = [f for f in sorted(os.listdir(os.getcwd())) if f.endswith('.jpg')]\n",
    "image_dir = {image: os.path.join(current_directory, \"../GANFD/Images\", image) for image in images}\n",
    "ganfd['full_ID_with_ext'] = ganfd['full_ID'] + '.jpg'\n",
    "ganfd['directory'] = ganfd['full_ID_with_ext'].map(image_dir)\n",
    "ganfd = ganfd.drop(columns=['full_ID_with_ext'])\n",
    "ganfd_dict = ganfd.set_index('full_ID')['directory'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Instructions and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dict = {\n",
    "    \"Story\": {\n",
    "        \"instruction\": \"You are a helpful chat assistant. You are going to generate texts in response to images depicting fictional individuals.\",\n",
    "        \"prompt\": \"Write a 50-word story about an individual inside the image.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pd(probs): \n",
    "    prob_diff = 1 - sum(x**2 for x in probs)\n",
    "    return prob_diff\n",
    "\n",
    "def calculate_entropy(probs):\n",
    "    return -np.sum(probs * np.log(probs))\n",
    "\n",
    "def calculate_perplexity(probs):\n",
    "    ent = calculate_entropy(probs)\n",
    "    perplexity = 2 ** ent\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 50\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for image_key, image_path in ganfd_dict.items():\n",
    "    base64_image = encode_image(image_path)\n",
    "    \n",
    "    # Create a list of messages for num_iter iterations\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_dict[\"Story\"][\"instruction\"]},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt_dict[\"Story\"][\"prompt\"]},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    ]\n",
    "\n",
    "    # Request with n = num_iter\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-2024-04-09\",  \n",
    "        messages=messages,\n",
    "        n=num_iter,\n",
    "        max_tokens=50,  # max_tokens should be same as token_index\n",
    "        logprobs=True,\n",
    "        top_logprobs=20  # max value\n",
    "    )\n",
    "\n",
    "    token_index = 50\n",
    "\n",
    "    # Initialize lists\n",
    "    pd_list = []\n",
    "    entropy_list = []\n",
    "    perplexity_list = []\n",
    "    index_list = []\n",
    "    image_list = []\n",
    "    iter_list = []\n",
    "    text_list = []\n",
    "\n",
    "    # Process all iterations in the response\n",
    "    for iter in range(num_iter):\n",
    "        try:\n",
    "            # Extract the text response for this iteration\n",
    "            full_text = response.choices[iter].message.content\n",
    "            \n",
    "            for index in range(token_index):\n",
    "                probs = [np.exp(i.logprob) for i in response.choices[iter].logprobs.content[index].top_logprobs]\n",
    "                iter_list.append(iter)\n",
    "                index_list.append(index)\n",
    "                pd_list.append(calculate_pd(probs))\n",
    "                entropy_list.append(calculate_entropy(probs))\n",
    "                perplexity_list.append(calculate_perplexity(probs))\n",
    "                image_list.append(image_key)\n",
    "                text_list.append(full_text)  # Add the full response text for each token\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "    # Create DataFrame for the current image and append to df_list\n",
    "    df = pd.DataFrame({\n",
    "        'image': image_list,\n",
    "        'iter': iter_list,\n",
    "        'index': index_list,\n",
    "        'pd': pd_list,\n",
    "        'entropy': entropy_list,\n",
    "        'perplexity': perplexity_list,\n",
    "        'text': text_list  # Include the full response text column\n",
    "    })\n",
    "    df_list.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory)\n",
    "final_df.to_csv('gpt4turbo.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
